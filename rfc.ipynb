{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19e3512e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import necessary libraries and functions\n",
    "from sklearn import datasets\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f39b563a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize dataframe for saving the accuracies into csv file\n",
    "df = pd.DataFrame({'90%': [],\n",
    "                    '80%': [],\n",
    "                    '70%': [],\n",
    "                    '60%': [],\n",
    "                    '50%': []})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a45bdd5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        N   P   K  temperature   humidity        ph    rainfall   label\n",
      "0      90  42  43    20.879744  82.002744  6.502985  202.935536    rice\n",
      "1      85  58  41    21.770462  80.319644  7.038096  226.655537    rice\n",
      "2      60  55  44    23.004459  82.320763  7.840207  263.964248    rice\n",
      "3      74  35  40    26.491096  80.158363  6.980401  242.864034    rice\n",
      "4      78  42  42    20.130175  81.604873  7.628473  262.717340    rice\n",
      "...   ...  ..  ..          ...        ...       ...         ...     ...\n",
      "2195  107  34  32    26.774637  66.413269  6.780064  177.774507  coffee\n",
      "2196   99  15  27    27.417112  56.636362  6.086922  127.924610  coffee\n",
      "2197  118  33  30    24.131797  67.225123  6.362608  173.322839  coffee\n",
      "2198  117  32  34    26.272418  52.127394  6.758793  127.175293  coffee\n",
      "2199  104  18  30    23.603016  60.396475  6.779833  140.937041  coffee\n",
      "\n",
      "[2200 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "#Load dataset\n",
    "crops = pd.read_csv('input/Crop_recommendation.csv')\n",
    "\n",
    "print(crops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3443613",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2200 entries, 0 to 2199\n",
      "Data columns (total 8 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   N            2200 non-null   int64  \n",
      " 1   P            2200 non-null   int64  \n",
      " 2   K            2200 non-null   int64  \n",
      " 3   temperature  2200 non-null   float64\n",
      " 4   humidity     2200 non-null   float64\n",
      " 5   ph           2200 non-null   float64\n",
      " 6   rainfall     2200 non-null   float64\n",
      " 7   label        2200 non-null   object \n",
      "dtypes: float64(4), int64(3), object(1)\n",
      "memory usage: 137.6+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "X=crops[['N', 'P', 'K', 'temperature', 'humidity', 'ph', 'rainfall']]  # input values\n",
    "Y=crops['label']  # output\n",
    "print(crops.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e2cf86a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of estimators = 1\n",
      "-> Accuracy: 0.96\n",
      "\n",
      "Number of estimators = 2\n",
      "-> Accuracy: 0.9727272727272728\n",
      "\n",
      "Number of estimators = 3\n",
      "-> Accuracy: 0.9872727272727273\n",
      "\n",
      "Number of estimators = 4\n",
      "-> Accuracy: 0.990909090909091\n",
      "\n",
      "Number of estimators = 5\n",
      "-> Accuracy: 0.9927272727272727\n",
      "\n",
      "Number of estimators = 6\n",
      "-> Accuracy: 0.9927272727272727\n",
      "\n",
      "Number of estimators = 7\n",
      "-> Accuracy: 0.9927272727272727\n",
      "\n",
      "Number of estimators = 8\n",
      "-> Accuracy: 0.990909090909091\n",
      "\n",
      "Number of estimators = 9\n",
      "-> Accuracy: 0.9927272727272727\n",
      "\n",
      "Number of estimators = 10\n",
      "-> Accuracy: 0.9927272727272727\n",
      "\n",
      "Number of estimators = 11\n",
      "-> Accuracy: 0.9927272727272727\n",
      "\n",
      "Number of estimators = 12\n",
      "-> Accuracy: 0.9927272727272727\n",
      "\n",
      "Number of estimators = 13\n",
      "-> Accuracy: 0.9927272727272727\n",
      "\n",
      "Number of estimators = 14\n",
      "-> Accuracy: 0.9927272727272727\n",
      "\n",
      "Number of estimators = 15\n",
      "-> Accuracy: 0.9927272727272727\n",
      "\n",
      "Number of estimators = 16\n",
      "-> Accuracy: 0.9927272727272727\n",
      "\n",
      "Number of estimators = 17\n",
      "-> Accuracy: 0.9927272727272727\n",
      "\n",
      "Number of estimators = 18\n",
      "-> Accuracy: 0.9927272727272727\n",
      "\n",
      "Number of estimators = 19\n",
      "-> Accuracy: 0.9927272727272727\n",
      "\n",
      "Number of estimators = 20\n",
      "-> Accuracy: 0.9927272727272727\n"
     ]
    }
   ],
   "source": [
    "#list for accuracies\n",
    "estimator_accuracies = []\n",
    "# Split dataset into training set and test set after shuffling it\n",
    "test_train_ratio = 0.25\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=test_train_ratio, shuffle=True)\n",
    "#test fabdin firest classifier with different amount of estimators (1-20)\n",
    "for n in range(1, 21):\n",
    "    print(\"\\nNumber of estimators = {}\".format(n))\n",
    "    #Create a Gaussian Classifier with n estimators\n",
    "    clf=RandomForestClassifier(n_estimators=n, random_state=0)\n",
    "    #Train the model using the training sets\n",
    "    clf.fit(X_train,y_train)\n",
    "    #predict outputs using testing data\n",
    "    y_pred=clf.predict(X_test)\n",
    "    print(\"-> Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "    estimator_accuracies.append(metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "09f23fa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test data: 10.0%\n",
      "-> Accuracy: 0.9954545454545455\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       apple       1.00      1.00      1.00        11\n",
      "      banana       1.00      1.00      1.00         9\n",
      "   blackgram       1.00      1.00      1.00        10\n",
      "    chickpea       1.00      1.00      1.00        11\n",
      "     coconut       1.00      1.00      1.00        13\n",
      "      coffee       1.00      1.00      1.00        10\n",
      "      cotton       1.00      1.00      1.00        14\n",
      "      grapes       1.00      1.00      1.00         8\n",
      "        jute       0.88      1.00      0.93         7\n",
      " kidneybeans       1.00      1.00      1.00         8\n",
      "      lentil       1.00      1.00      1.00         8\n",
      "       maize       1.00      1.00      1.00        12\n",
      "       mango       1.00      1.00      1.00        13\n",
      "   mothbeans       1.00      1.00      1.00        12\n",
      "    mungbean       1.00      1.00      1.00        14\n",
      "   muskmelon       1.00      1.00      1.00         8\n",
      "      orange       1.00      1.00      1.00         8\n",
      "      papaya       1.00      1.00      1.00         8\n",
      "  pigeonpeas       1.00      1.00      1.00         8\n",
      " pomegranate       1.00      1.00      1.00         6\n",
      "        rice       1.00      0.92      0.96        13\n",
      "  watermelon       1.00      1.00      1.00         9\n",
      "\n",
      "    accuracy                           1.00       220\n",
      "   macro avg       0.99      1.00      1.00       220\n",
      "weighted avg       1.00      1.00      1.00       220\n",
      "\n",
      "\n",
      "Test data: 20.0%\n",
      "-> Accuracy: 0.990909090909091\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       apple       1.00      1.00      1.00        21\n",
      "      banana       1.00      1.00      1.00        25\n",
      "   blackgram       0.96      1.00      0.98        23\n",
      "    chickpea       1.00      1.00      1.00        22\n",
      "     coconut       1.00      1.00      1.00        22\n",
      "      coffee       1.00      1.00      1.00        21\n",
      "      cotton       1.00      1.00      1.00        14\n",
      "      grapes       1.00      1.00      1.00        20\n",
      "        jute       0.90      1.00      0.95        18\n",
      " kidneybeans       1.00      1.00      1.00        17\n",
      "      lentil       0.95      1.00      0.98        20\n",
      "       maize       1.00      1.00      1.00        18\n",
      "       mango       1.00      1.00      1.00        14\n",
      "   mothbeans       1.00      0.94      0.97        33\n",
      "    mungbean       1.00      1.00      1.00        19\n",
      "   muskmelon       1.00      1.00      1.00        16\n",
      "      orange       1.00      1.00      1.00        22\n",
      "      papaya       1.00      1.00      1.00        17\n",
      "  pigeonpeas       1.00      1.00      1.00        14\n",
      " pomegranate       1.00      1.00      1.00        18\n",
      "        rice       1.00      0.92      0.96        25\n",
      "  watermelon       1.00      1.00      1.00        21\n",
      "\n",
      "    accuracy                           0.99       440\n",
      "   macro avg       0.99      0.99      0.99       440\n",
      "weighted avg       0.99      0.99      0.99       440\n",
      "\n",
      "\n",
      "Test data: 30.0%\n",
      "-> Accuracy: 0.9924242424242424\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       apple       1.00      1.00      1.00        29\n",
      "      banana       1.00      1.00      1.00        34\n",
      "   blackgram       1.00      1.00      1.00        31\n",
      "    chickpea       1.00      1.00      1.00        30\n",
      "     coconut       1.00      1.00      1.00        28\n",
      "      coffee       1.00      1.00      1.00        27\n",
      "      cotton       1.00      1.00      1.00        30\n",
      "      grapes       1.00      1.00      1.00        29\n",
      "        jute       0.88      0.97      0.92        30\n",
      " kidneybeans       1.00      1.00      1.00        40\n",
      "      lentil       1.00      1.00      1.00        31\n",
      "       maize       1.00      1.00      1.00        30\n",
      "       mango       1.00      1.00      1.00        28\n",
      "   mothbeans       1.00      1.00      1.00        33\n",
      "    mungbean       1.00      1.00      1.00        30\n",
      "   muskmelon       1.00      1.00      1.00        27\n",
      "      orange       1.00      1.00      1.00        26\n",
      "      papaya       1.00      1.00      1.00        27\n",
      "  pigeonpeas       1.00      1.00      1.00        28\n",
      " pomegranate       1.00      1.00      1.00        29\n",
      "        rice       0.97      0.89      0.93        37\n",
      "  watermelon       1.00      1.00      1.00        26\n",
      "\n",
      "    accuracy                           0.99       660\n",
      "   macro avg       0.99      0.99      0.99       660\n",
      "weighted avg       0.99      0.99      0.99       660\n",
      "\n",
      "\n",
      "Test data: 40.0%\n",
      "-> Accuracy: 0.9886363636363636\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       apple       1.00      1.00      1.00        45\n",
      "      banana       1.00      1.00      1.00        37\n",
      "   blackgram       1.00      1.00      1.00        38\n",
      "    chickpea       1.00      1.00      1.00        38\n",
      "     coconut       1.00      1.00      1.00        38\n",
      "      coffee       1.00      1.00      1.00        40\n",
      "      cotton       0.97      1.00      0.99        35\n",
      "      grapes       1.00      1.00      1.00        50\n",
      "        jute       0.84      0.97      0.90        37\n",
      " kidneybeans       1.00      1.00      1.00        45\n",
      "      lentil       1.00      0.97      0.99        39\n",
      "       maize       1.00      0.97      0.99        37\n",
      "       mango       1.00      1.00      1.00        43\n",
      "   mothbeans       0.98      1.00      0.99        47\n",
      "    mungbean       1.00      1.00      1.00        33\n",
      "   muskmelon       1.00      1.00      1.00        46\n",
      "      orange       1.00      1.00      1.00        34\n",
      "      papaya       1.00      0.93      0.96        41\n",
      "  pigeonpeas       1.00      1.00      1.00        44\n",
      " pomegranate       1.00      1.00      1.00        35\n",
      "        rice       0.97      0.90      0.93        39\n",
      "  watermelon       1.00      1.00      1.00        39\n",
      "\n",
      "    accuracy                           0.99       880\n",
      "   macro avg       0.99      0.99      0.99       880\n",
      "weighted avg       0.99      0.99      0.99       880\n",
      "\n",
      "\n",
      "Test data: 50.0%\n",
      "-> Accuracy: 0.9890909090909091\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       apple       1.00      1.00      1.00        49\n",
      "      banana       1.00      1.00      1.00        45\n",
      "   blackgram       1.00      0.98      0.99        53\n",
      "    chickpea       1.00      1.00      1.00        56\n",
      "     coconut       1.00      1.00      1.00        47\n",
      "      coffee       1.00      1.00      1.00        49\n",
      "      cotton       1.00      1.00      1.00        57\n",
      "      grapes       1.00      1.00      1.00        44\n",
      "        jute       0.83      0.98      0.90        46\n",
      " kidneybeans       1.00      1.00      1.00        50\n",
      "      lentil       1.00      0.98      0.99        50\n",
      "       maize       0.98      1.00      0.99        53\n",
      "       mango       1.00      1.00      1.00        48\n",
      "   mothbeans       0.98      1.00      0.99        41\n",
      "    mungbean       1.00      1.00      1.00        53\n",
      "   muskmelon       1.00      1.00      1.00        45\n",
      "      orange       1.00      1.00      1.00        52\n",
      "      papaya       1.00      1.00      1.00        55\n",
      "  pigeonpeas       1.00      1.00      1.00        48\n",
      " pomegranate       1.00      1.00      1.00        60\n",
      "        rice       0.97      0.81      0.89        48\n",
      "  watermelon       1.00      1.00      1.00        51\n",
      "\n",
      "    accuracy                           0.99      1100\n",
      "   macro avg       0.99      0.99      0.99      1100\n",
      "weighted avg       0.99      0.99      0.99      1100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#list for accuracies\n",
    "accuracies = []\n",
    "#test random forest with five different test/train data ratios, repeat 10 times\n",
    "for i in range(1,6):\n",
    "        #calculate ratio\n",
    "        test_train_ratio = float(10*i / 100)\n",
    "        print(\"\\nTest data: {}%\".format(100*test_train_ratio))\n",
    "\n",
    "        # Split dataset into training set and test set after shuffling it\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=test_train_ratio, shuffle=True)\n",
    "\n",
    "        #Create a Gaussian Classifier\n",
    "        clf=RandomForestClassifier(n_estimators=8, random_state=0)\n",
    "\n",
    "        #Train the model using the training sets\n",
    "        clf.fit(X_train,y_train)\n",
    "\n",
    "        #predict outputs using testing data\n",
    "        y_pred=clf.predict(X_test)\n",
    "        print(\"-> Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "        print(classification_report(y_test,y_pred))\n",
    "        accuracies.append(metrics.accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "44c6679a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data: 90.0%, accuracy: 0.9954545454545455\n",
      "Test data: 80.0%, accuracy: 0.990909090909091\n",
      "Test data: 70.0%, accuracy: 0.9924242424242424\n",
      "Test data: 60.0%, accuracy: 0.9886363636363636\n",
      "Test data: 50.0%, accuracy: 0.9890909090909091\n"
     ]
    }
   ],
   "source": [
    "# calculate, how many times output was predicted correctly with testing data\n",
    "for i in range(1,6):\n",
    "    test_train_ratio = float((100 - 10*i) / 100)\n",
    "    print(\"Test data: {}%, accuracy: {}\".format(100 * test_train_ratio, accuracies[i-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e8fc7f7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#display accuracies\n",
    "fig = plt.figure()\n",
    "plt.title('Accuracies')\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "ratios = ['90%', '80%', '70%', '60%', '50%']\n",
    "ax.bar(ratios,accuracies)\n",
    "ax.set_ylim([0.9, 1.0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "46402ea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        90%       80%       70%       60%       50%\n",
      "0  0.990909  0.995455  0.987879  0.994318  0.988182\n",
      "1  0.990909  0.995455  0.989394  0.989773  0.994545\n",
      "2  0.990909  1.000000  0.995455  0.993182  0.986364\n",
      "3  0.995455  0.997727  0.990909  0.989773  0.983636\n",
      "4  0.986364  0.995455  0.993939  0.990909  0.987273\n",
      "5  0.995455  0.995455  0.989394  0.994318  0.985455\n",
      "6  0.995455  0.995455  0.992424  0.981818  0.986364\n",
      "7  1.000000  0.995455  0.989394  0.994318  0.980000\n",
      "8  0.986364  0.990909  0.993939  0.990909  0.990000\n",
      "9  0.995455  0.990909  0.992424  0.988636  0.989091\n"
     ]
    }
   ],
   "source": [
    "#add new results to dataframe, repeat this 10 times\n",
    "df.loc[len(df.index)] = [accuracies[0], accuracies[1], accuracies[2], accuracies[3], accuracies[4]]\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e661478c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save latest dataframe to csv file\n",
    "df.to_csv('input/rfc_accuracies.csv', index=False, mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e959a43d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
